{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1718454729774,"user":{"displayName":"Rosa Prieto","userId":"11930815821174800710"},"user_tz":240},"id":"cvEsGLkm36Pm","outputId":"929e2dfa-cfbe-4ab3-d21c-b0948c5440db"},"outputs":[],"source":["import os\n","# check if session has spark\n","# os.listdir('/content/')\n","#os.listdir()"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":81837,"status":"ok","timestamp":1718454811609,"user":{"displayName":"Rosa Prieto","userId":"11930815821174800710"},"user_tz":240},"id":"uC7pSteJ371l","outputId":"e01918ba-3821-4cd7-86f1-1faf601c00cf"},"outputs":[{"name":"stderr","output_type":"stream","text":["'apt-get' is not recognized as an internal or external command,\n","operable program or batch file.\n"]},{"name":"stderr","output_type":"stream","text":["The system cannot find the path specified.\n","'wget' is not recognized as an internal or external command,\n","operable program or batch file.\n","tar: Error opening archive: Failed to open 'spark-3.5.1-bin-hadoop3.tgz'\n","\n","[notice] A new release of pip available: 22.3.1 -> 24.1\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n"]},{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: pyspark in c:\\users\\htwal\\onedrive\\documents\\gmu\\bbcudas_usps\\env\\lib\\site-packages (3.5.1)\n","Requirement already satisfied: py4j==0.10.9.7 in c:\\users\\htwal\\onedrive\\documents\\gmu\\bbcudas_usps\\env\\lib\\site-packages (from pyspark) (0.10.9.7)\n"]},{"name":"stderr","output_type":"stream","text":["\n","[notice] A new release of pip available: 22.3.1 -> 24.1\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n"]}],"source":["# Install Spark and Java\n","!apt-get update\n","!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n","!wget -q https://downloads.apache.org/spark/spark-3.5.1/spark-3.5.1-bin-hadoop3.tgz\n","!tar xf spark-3.5.1-bin-hadoop3.tgz\n","\n","!pip install -q findspark\n","!pip install pyspark"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1873,"status":"ok","timestamp":1718455058235,"user":{"displayName":"Rosa Prieto","userId":"11930815821174800710"},"user_tz":240},"id":"LHlEpJmR3-Ck","outputId":"b5d6b106-226c-4b33-a74b-5662a5642e7c"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'google.colab'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# one time thing\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Mount Google Drive\u001b[39;00m\n\u001b[0;32m      4\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"]}],"source":["# one time thing\n","from google.colab import drive\n","# Mount Google Drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":4402,"status":"ok","timestamp":1718455062635,"user":{"displayName":"Rosa Prieto","userId":"11930815821174800710"},"user_tz":240},"id":"22m1YoIo4AHz"},"outputs":[],"source":["# Set environment variables\n","import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.1-bin-hadoop3\"\n","\n","# Start a Spark session\n","import findspark\n","findspark.init()\n","\n","# Create a SparkSession\n","import pyspark\n","from pyspark.sql import SparkSession\n","from pyspark.sql.functions import *\n","from pyspark.sql.types import *\n","#sc = SparkContext.getOrCreate()\n","spark = SparkSession.builder.appName(\"MyApp\").getOrCreate()\n","spark.sparkContext.setCheckpointDir(\"/content/drive/My Drive/USPS/spark_checkpoint\")\n","\n","os.chdir('/content/drive/My Drive/USPS')\n","\n"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":9404,"status":"ok","timestamp":1718455072028,"user":{"displayName":"Rosa Prieto","userId":"11930815821174800710"},"user_tz":240},"id":"VJq0hvAf4CVK"},"outputs":[],"source":["# Read parquet file to DF\n","folder1 = \"/content/drive/My Drive/USPS/parq_files/usps_0501.parquet\"\n","folder2 = \"/content/drive/My Drive/USPS/parq_files/usps_0502.parquet\"\n","folder3 = \"/content/drive/My Drive/USPS/parq_files/usps_0503.parquet\"\n","parc_folders = [folder1,folder2,folder3]\n","df = spark.read.parquet(*parc_folders)\n","\n","#Cleaning -----\n","# data from 0503 read ServiceType code as int so it removed 0s to the left;adding those back\n","df = df.withColumn('ServiceTypeCode', lpad(col('ServiceTypeCode'), 3, '0'))\n","\n","# Get the list of columns that contain 'zipcode'\n","zipcode_columns = [col for col in df.columns if 'zipcode' in col]\n","\n","# Define a function to add leading zeros\n","def add_leading_zeros(col):\n","    return lpad(col, 5, '0')\n","\n","# Apply the function to all zipcode columns\n","for col in zipcode_columns:\n","    df = df.withColumn(col, add_leading_zeros(df[col]))\n","\n","# recode CMRA flag\n","df = df.withColumn(\n","    'CRID_cmra_flag',\n","    when(df['CRID_cmra_flag'] == 'Y', True)\n","    .when(df['CRID_cmra_flag'].isin(['N', 'X']), False)\n","    .otherwise(None)\n",")\n","\n","# recode delinked nulls\n","df = df.withColumn(\"delinked\", when(df[\"delinked\"].isNull(), False).otherwise(df[\"delinked\"]))\n","\n"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1718455072028,"user":{"displayName":"Rosa Prieto","userId":"11930815821174800710"},"user_tz":240},"id":"RP7_j6fI4QK2"},"outputs":[],"source":["# create potential fraud column\n","df = df.withColumn(\n","    \"potential_fraud\",\n","    when(df[\"delinked\"] == True, True)\n","    .when(df[\"icr_or_manifest\"] == False, True)\n","    .when(df[\"symbology_mismatch\"] == True, True)\n","    .when(df[\"firstzip_startzip_diff\"] == True, True)\n","    .otherwise(False)\n",")"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":134654,"status":"ok","timestamp":1718455206669,"user":{"displayName":"Rosa Prieto","userId":"11930815821174800710"},"user_tz":240},"id":"61tjGrt54Wzs","outputId":"1ec2187d-f38d-49ce-a4e6-f23fc64d51a6"},"outputs":[{"data":{"text/plain":["61256141"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["total_rows = df.count()\n","total_rows #61,256,141"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":153984,"status":"ok","timestamp":1718455360650,"user":{"displayName":"Rosa Prieto","userId":"11930815821174800710"},"user_tz":240},"id":"sHGrACGW4maA","outputId":"f75df1fc-d16f-46fa-b340-6343c865b1d6"},"outputs":[{"name":"stdout","output_type":"stream","text":["+---------------+--------+\n","|potential_fraud|   count|\n","+---------------+--------+\n","|           true|21918680|\n","|          false|39337461|\n","+---------------+--------+\n","\n"]}],"source":["df.groupby('potential_fraud').count().show()"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":328,"status":"ok","timestamp":1718461232630,"user":{"displayName":"Rosa Prieto","userId":"11930815821174800710"},"user_tz":240},"id":"RUnEhm0-RWuW"},"outputs":[],"source":["n_non_fraud = 39337461"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":6698,"status":"ok","timestamp":1718461240463,"user":{"displayName":"Rosa Prieto","userId":"11930815821174800710"},"user_tz":240},"id":"hoWFm5bR4ofx"},"outputs":[],"source":["# Select records with \"potential fraud\" == True\n","fraud_records = df.filter(df[\"potential_fraud\"] == True)\n","n_fraud = fraud_records.count()\n","# Select a random assortment of records with \"potential fraud\" == False\n","non_fraud_records = df.filter(df[\"potential_fraud\"] == False).sample(fraction = n_fraud/n_non_fraud)# total of non_fraud\n","\n","# Combine the two sets of records\n","working_dataset = fraud_records.union(non_fraud_records)"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1718461241571,"user":{"displayName":"Rosa Prieto","userId":"11930815821174800710"},"user_tz":240},"id":"Wp6wbQlJ4rbC"},"outputs":[],"source":["working_dataset = working_dataset.coalesce(1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CCtVRGe7Tjzd"},"outputs":[],"source":["working_dataset.write.csv(\"/content/drive/My Drive/USPS/working_dataset.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R-5ZFjTITp_x"},"outputs":[],"source":["subset_100k_noW= df.sample(fraction=0.1)\n","subset_100k_noW = subset_100k_noW.coalesce(1)\n","subset_100k_noW.write.csv(\"/content/drive/My Drive/USPS/subset_100k_noW.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Do2CZe57T6-S"},"outputs":[],"source":["subset_10perc_W= working_dataset.sample(fraction=0.1)\n","subset_10perc_W = subset_10perc_W.coalesce(1)\n","subset_10perc_W.write.csv(\"/content/drive/My Drive/USPS/subset_10perc_W.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vYU8dGzXWfbH"},"outputs":[],"source":["subset_1perc_W= working_dataset.sample(fraction=0.01)\n","subset_1perc_W = subset_1perc_W.coalesce(1)\n","subset_1perc_W.write.csv(\"/content/drive/My Drive/USPS/subset_1perc_W.csv\")"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOezSLXh9zjPyN1q9oKvv4A","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.1"}},"nbformat":4,"nbformat_minor":0}
